{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08a0bbd-ff7b-41f5-a9a2-cd73c4909473",
   "metadata": {},
   "source": [
    "# TorNet Baseline CNN\n",
    "\n",
    "This notebook trains the baseline keras CNN model on subset and tests it on different categories of TorNet samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e10c812",
   "metadata": {},
   "source": [
    "## Part 1 - Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a3573c",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c59aced-a4b8-4045-aea7-8faf85e84bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import shutil\n",
    "import keras\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from tornet.data.loader import get_dataloader\n",
    "from tornet.data.preprocess import get_shape\n",
    "from tornet.data.constants import ALL_VARIABLES\n",
    "from tornet.models.keras.losses import mae_loss\n",
    "from tornet.models.keras.cnn_baseline import build_model\n",
    "from tornet.metrics.keras import metrics as tfm\n",
    "from tornet.utils.general import make_exp_dir, make_callback_dirs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9563e406",
   "metadata": {},
   "source": [
    "### Setting Up Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1440ae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:TORNET_ROOT=/Users/dana/Desktop/ML/tornet_project/dataset\n"
     ]
    }
   ],
   "source": [
    "# os.environ['KERAS_BACKEND']='tensorflow' # set to 'tensorflow', 'torch' or 'jax' (installs required)\n",
    "os.environ['TORNET_ROOT'] = '/Users/dana/Desktop/ML/tornet_project/dataset'\n",
    "EXP_DIR=os.environ.get('EXP_DIR','.')\n",
    "DATA_ROOT=os.environ['TORNET_ROOT']\n",
    "logging.info('TORNET_ROOT='+DATA_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1af02f",
   "metadata": {},
   "source": [
    "### Setting Up CNN Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7fe134e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CONFIG={\n",
    "    'epochs':10,\n",
    "    'input_variables':ALL_VARIABLES,\n",
    "    'train_years':list(range(2021,2022)),\n",
    "    'val_years':list(range(2021,2022)),\n",
    "    'batch_size':128,\n",
    "    'model':'vgg',\n",
    "    'start_filters':48,\n",
    "    'learning_rate':1e-4,\n",
    "    'decay_steps':1386,\n",
    "    'decay_rate':0.958,\n",
    "    'l2_reg':1e-5,\n",
    "    'wN':1.0,\n",
    "    'w0':1.0,\n",
    "    'w1':1.0,\n",
    "    'w2':2.0,\n",
    "    'wW':0.5,\n",
    "    'label_smooth':0,\n",
    "    'loss':'cce',\n",
    "    'head':'maxpool',\n",
    "    'exp_name':'tornet_baseline',\n",
    "    'exp_dir':EXP_DIR,\n",
    "    'dataloader':\"keras\",\n",
    "    'dataloader_kwargs': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c6889",
   "metadata": {},
   "source": [
    "### Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6ce0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_keras_baselinecnn_model(config):\n",
    "    '''\n",
    "    Train a keras baseline CNN model with the given configuration    \n",
    "    '''\n",
    "    # Gather all hyperparams\n",
    "    epochs = config.get('epochs')\n",
    "    batch_size = config.get('batch_size')\n",
    "    start_filters = config.get('start_filters')\n",
    "    learning_rate = config.get('learning_rate')\n",
    "    decay_steps = config.get('decay_steps')\n",
    "    decay_rate = config.get('decay_rate')\n",
    "    l2_reg = config.get('l2_reg')\n",
    "    wN = config.get('wN')\n",
    "    w0 = config.get('w0')\n",
    "    w1 = config.get('w1')\n",
    "    w2 = config.get('w2')\n",
    "    wW = config.get('wW')\n",
    "    head = config.get('head')\n",
    "    label_smooth = config.get('label_smooth')\n",
    "    loss_fn = config.get('loss')\n",
    "    input_variables = config.get('input_variables')\n",
    "    exp_name = config.get('exp_name')\n",
    "    exp_dir = config.get('exp_dir')\n",
    "    train_years = config.get('train_years')\n",
    "    val_years = config.get('val_years')\n",
    "    dataloader = config.get('dataloader')\n",
    "    dataloader_kwargs = config.get('dataloader_kwargs')\n",
    "\n",
    "    logging.info(f\"Using {keras.config.backend()} backend\")\n",
    "    logging.info(f'Using {dataloader} dataloader')\n",
    "    logging.info('Running with config:')\n",
    "    logging.info(config)\n",
    "\n",
    "    weights = {'wN': wN, 'w0': w0, 'w1': w1, 'w2': w2, 'wW': wW}\n",
    "\n",
    "    # Create data laoders\n",
    "    dataloader_kwargs = {'select_keys': input_variables +\n",
    "                         ['range_folded_mask', 'coordinates']}\n",
    "    ds_train = get_dataloader(dataloader, DATA_ROOT, train_years,\n",
    "                              \"train\", batch_size, weights, **dataloader_kwargs)\n",
    "    ds_val = get_dataloader(dataloader, DATA_ROOT, val_years,\n",
    "                            \"train\", batch_size, weights, **dataloader_kwargs)\n",
    "\n",
    "    in_shapes = (None, None, 2)\n",
    "    c_shapes = (None, None, 2)\n",
    "    nn = build_model(shape=in_shapes,\n",
    "                     c_shape=c_shapes,\n",
    "                     start_filters=start_filters,\n",
    "                     l2_reg=l2_reg,\n",
    "                     input_variables=input_variables,\n",
    "                     head=head)\n",
    "\n",
    "    # model setup\n",
    "    lr = keras.optimizers.schedules.ExponentialDecay(\n",
    "        learning_rate, decay_steps, decay_rate, staircase=False, name=\"exp_decay\")\n",
    "\n",
    "    from_logits = True\n",
    "    if loss_fn.lower() == 'cce':\n",
    "        loss = keras.losses.BinaryCrossentropy(from_logits=from_logits,\n",
    "                                               label_smoothing=label_smooth)\n",
    "    elif loss_fn.lower() == 'hinge':\n",
    "        loss = keras.losses.Hinge()  # automatically converts labels to -1,1\n",
    "    elif loss_fn.lower() == 'mae':\n",
    "        def loss(yt, yp): return mae_loss(yt, yp)\n",
    "    else:\n",
    "        raise RuntimeError('unknown loss %s' % loss_fn)\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    # Compute various metrics while training\n",
    "    metrics = [keras.metrics.AUC(from_logits=from_logits, name='AUC', num_thresholds=2000),\n",
    "               keras.metrics.AUC(from_logits=from_logits,\n",
    "                                 curve='PR', name='AUCPR', num_thresholds=2000),\n",
    "               tfm.BinaryAccuracy(from_logits, name='BinaryAccuracy'),\n",
    "               tfm.TruePositives(from_logits, name='TruePositives'),\n",
    "               tfm.FalsePositives(from_logits, name='FalsePositives'),\n",
    "               tfm.TrueNegatives(from_logits, name='TrueNegatives'),\n",
    "               tfm.FalseNegatives(from_logits, name='FalseNegatives'),\n",
    "               tfm.Precision(from_logits, name='Precision'),\n",
    "               tfm.Recall(from_logits, name='Recall'),\n",
    "               tfm.F1Score(from_logits=from_logits, name='F1')]\n",
    "\n",
    "    # Compile\n",
    "    nn.compile(loss=loss,\n",
    "               metrics=metrics,\n",
    "               optimizer=opt,\n",
    "               weighted_metrics=[])\n",
    "\n",
    "    # FIT with ModelCheckpoint in callbacks\n",
    "    callbacks = []  # Add other callbacks here if necessary\n",
    "    nn.fit(ds_train,epochs=epochs,validation_data=ds_val,callbacks=callbacks,verbose=1)\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6321ad47",
   "metadata": {},
   "source": [
    "### Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3499696d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using tensorflow backend\n",
      "INFO:root:Using keras dataloader\n",
      "INFO:root:Running with config:\n",
      "INFO:root:{'epochs': 10, 'input_variables': ['DBZ', 'VEL', 'KDP', 'RHOHV', 'ZDR', 'WIDTH'], 'train_years': [2021], 'val_years': [2021], 'batch_size': 128, 'model': 'vgg', 'start_filters': 48, 'learning_rate': 0.0001, 'decay_steps': 1386, 'decay_rate': 0.958, 'l2_reg': 1e-05, 'wN': 1.0, 'w0': 1.0, 'w1': 1.0, 'w2': 2.0, 'wW': 0.5, 'label_smooth': 0, 'loss': 'cce', 'head': 'maxpool', 'exp_name': 'tornet_baseline', 'exp_dir': '.', 'dataloader': 'keras', 'dataloader_kwargs': {}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 22:42:05.655145: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:52: Filling up shuffle buffer (this may take a while): 6 of 8\n",
      "2024-08-01 22:42:09.355059: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2213s\u001b[0m 15s/step - AUC: 0.6055 - AUCPR: 0.0902 - BinaryAccuracy: 0.8957 - F1: 0.0249 - FalseNegatives: 680.8400 - FalsePositives: 121.0000 - Precision: 0.0547 - Recall: 0.0308 - TrueNegatives: 8847.4463 - TruePositives: 7.0000 - loss: 0.3326 - val_AUC: 0.6824 - val_AUCPR: 0.1194 - val_BinaryAccuracy: 0.9299 - val_F1: 0.0000e+00 - val_FalseNegatives: 1335.0000 - val_FalsePositives: 0.0000e+00 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_TrueNegatives: 17716.0000 - val_TruePositives: 0.0000e+00 - val_loss: 0.2865\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 23:18:56.449845: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:52: Filling up shuffle buffer (this may take a while): 6 of 8\n",
      "2024-08-01 23:19:00.038464: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2163s\u001b[0m 14s/step - AUC: 0.6912 - AUCPR: 0.1359 - BinaryAccuracy: 0.9275 - F1: 0.0000e+00 - FalseNegatives: 681.2534 - FalsePositives: 0.0000e+00 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - TrueNegatives: 8976.8535 - TruePositives: 0.0000e+00 - loss: 0.2839 - val_AUC: 0.7524 - val_AUCPR: 0.1914 - val_BinaryAccuracy: 0.9299 - val_F1: 0.0000e+00 - val_FalseNegatives: 1335.0000 - val_FalsePositives: 0.0000e+00 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_TrueNegatives: 17716.0000 - val_TruePositives: 0.0000e+00 - val_loss: 0.2631\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 23:55:00.018590: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:52: Filling up shuffle buffer (this may take a while): 6 of 8\n",
      "2024-08-01 23:55:03.742669: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2196s\u001b[0m 15s/step - AUC: 0.7473 - AUCPR: 0.1884 - BinaryAccuracy: 0.9327 - F1: 0.0000e+00 - FalseNegatives: 670.7333 - FalsePositives: 0.3200 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - TrueNegatives: 8973.7529 - TruePositives: 0.0000e+00 - loss: 0.2527 - val_AUC: 0.7506 - val_AUCPR: 0.2157 - val_BinaryAccuracy: 0.9299 - val_F1: 0.0000e+00 - val_FalseNegatives: 1335.0000 - val_FalsePositives: 0.0000e+00 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_TrueNegatives: 17716.0000 - val_TruePositives: 0.0000e+00 - val_loss: 0.2553\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 00:31:36.438920: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:52: Filling up shuffle buffer (this may take a while): 6 of 8\n",
      "2024-08-02 00:31:40.181231: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2192s\u001b[0m 15s/step - AUC: 0.7583 - AUCPR: 0.2146 - BinaryAccuracy: 0.9272 - F1: 0.0000e+00 - FalseNegatives: 691.3200 - FalsePositives: 0.0000e+00 - Precision: 0.0000e+00 - Recall: 0.0000e+00 - TrueNegatives: 8958.2471 - TruePositives: 0.0000e+00 - loss: 0.2589 - val_AUC: 0.7882 - val_AUCPR: 0.2375 - val_BinaryAccuracy: 0.9299 - val_F1: 0.0000e+00 - val_FalseNegatives: 1335.0000 - val_FalsePositives: 0.0000e+00 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_TrueNegatives: 17716.0000 - val_TruePositives: 0.0000e+00 - val_loss: 0.2450\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 01:08:07.935508: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:52: Filling up shuffle buffer (this may take a while): 6 of 8\n",
      "2024-08-02 01:08:11.615364: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2189s\u001b[0m 15s/step - AUC: 0.7810 - AUCPR: 0.2163 - BinaryAccuracy: 0.9294 - F1: 0.0437 - FalseNegatives: 653.0600 - FalsePositives: 32.4400 - Precision: 0.2766 - Recall: 0.0243 - TrueNegatives: 8962.5801 - TruePositives: 13.8067 - loss: 0.2432 - val_AUC: 0.7992 - val_AUCPR: 0.2416 - val_BinaryAccuracy: 0.9295 - val_F1: 0.0190 - val_FalseNegatives: 1322.0000 - val_FalsePositives: 21.0000 - val_Precision: 0.3824 - val_Recall: 0.0097 - val_TrueNegatives: 17695.0000 - val_TruePositives: 13.0000 - val_loss: 0.2481\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 01:44:37.443174: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:52: Filling up shuffle buffer (this may take a while): 6 of 8\n",
      "2024-08-02 01:44:41.133147: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2190s\u001b[0m 15s/step - AUC: 0.7879 - AUCPR: 0.2291 - BinaryAccuracy: 0.9290 - F1: 0.0480 - FalseNegatives: 656.0000 - FalsePositives: 36.7133 - Precision: 0.3797 - Recall: 0.0259 - TrueNegatives: 8938.0938 - TruePositives: 17.2200 - loss: 0.2411 - val_AUC: 0.8054 - val_AUCPR: 0.2753 - val_BinaryAccuracy: 0.9310 - val_F1: 0.0560 - val_FalseNegatives: 1296.0000 - val_FalsePositives: 19.0000 - val_Precision: 0.6724 - val_Recall: 0.0292 - val_TrueNegatives: 17697.0000 - val_TruePositives: 39.0000 - val_loss: 0.2380\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 02:21:07.802152: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:52: Filling up shuffle buffer (this may take a while): 6 of 8\n",
      "2024-08-02 02:21:11.475652: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2194s\u001b[0m 15s/step - AUC: 0.7929 - AUCPR: 0.2429 - BinaryAccuracy: 0.9297 - F1: 0.0985 - FalseNegatives: 633.6866 - FalsePositives: 60.2867 - Precision: 0.4613 - Recall: 0.0564 - TrueNegatives: 8920.8730 - TruePositives: 44.1000 - loss: 0.2382 - val_AUC: 0.8034 - val_AUCPR: 0.2750 - val_BinaryAccuracy: 0.9294 - val_F1: 0.0881 - val_FalseNegatives: 1270.0000 - val_FalsePositives: 75.0000 - val_Precision: 0.4643 - val_Recall: 0.0487 - val_TrueNegatives: 17641.0000 - val_TruePositives: 65.0000 - val_loss: 0.2401\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 02:57:42.648869: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:52: Filling up shuffle buffer (this may take a while): 6 of 8\n",
      "2024-08-02 02:57:46.419270: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2198s\u001b[0m 15s/step - AUC: 0.8033 - AUCPR: 0.2678 - BinaryAccuracy: 0.9248 - F1: 0.1397 - FalseNegatives: 614.0200 - FalsePositives: 108.3000 - Precision: 0.3624 - Recall: 0.0875 - TrueNegatives: 8871.3662 - TruePositives: 63.8600 - loss: 0.2376 - val_AUC: 0.8086 - val_AUCPR: 0.2569 - val_BinaryAccuracy: 0.9278 - val_F1: 0.0900 - val_FalseNegatives: 1267.0000 - val_FalsePositives: 108.0000 - val_Precision: 0.3864 - val_Recall: 0.0509 - val_TrueNegatives: 17608.0000 - val_TruePositives: 68.0000 - val_loss: 0.2338\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 03:34:20.355261: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:52: Filling up shuffle buffer (this may take a while): 6 of 8\n",
      "2024-08-02 03:34:24.102567: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2199s\u001b[0m 15s/step - AUC: 0.8047 - AUCPR: 0.2579 - BinaryAccuracy: 0.9294 - F1: 0.1561 - FalseNegatives: 607.3134 - FalsePositives: 92.0400 - Precision: 0.4446 - Recall: 0.0966 - TrueNegatives: 8884.8398 - TruePositives: 70.1333 - loss: 0.2302 - val_AUC: 0.8224 - val_AUCPR: 0.3093 - val_BinaryAccuracy: 0.9218 - val_F1: 0.3058 - val_FalseNegatives: 1007.0000 - val_FalsePositives: 482.0000 - val_Precision: 0.4049 - val_Recall: 0.2457 - val_TrueNegatives: 17234.0000 - val_TruePositives: 328.0000 - val_loss: 0.2263\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 04:10:59.147243: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:52: Filling up shuffle buffer (this may take a while): 6 of 8\n",
      "2024-08-02 04:11:02.882926: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2199s\u001b[0m 15s/step - AUC: 0.8192 - AUCPR: 0.2736 - BinaryAccuracy: 0.9235 - F1: 0.2347 - FalseNegatives: 558.9200 - FalsePositives: 174.0067 - Precision: 0.3813 - Recall: 0.1703 - TrueNegatives: 8801.4805 - TruePositives: 113.4800 - loss: 0.2232 - val_AUC: 0.8348 - val_AUCPR: 0.3316 - val_BinaryAccuracy: 0.9313 - val_F1: 0.0750 - val_FalseNegatives: 1282.0000 - val_FalsePositives: 26.0000 - val_Precision: 0.6709 - val_Recall: 0.0397 - val_TrueNegatives: 17690.0000 - val_TruePositives: 53.0000 - val_loss: 0.2279\n"
     ]
    }
   ],
   "source": [
    "baselinecnn = train_keras_baselinecnn_model(DEFAULT_CONFIG)\n",
    "baselinecnn.save('baselinecnn.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c29e69",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0a814da6-aca9-44df-b563-318351cf6dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Uncomment if tornet isn't installed in your environment or in your path already\n",
    "# sys.path.append('../')  \n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from tornet.metrics.keras import metrics as tfm\n",
    "import logging\n",
    "\n",
    "\n",
    "from tornet.data.keras.loader import KerasDataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140c56b",
   "metadata": {},
   "source": [
    "### Evaluating on different tornado categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "84506b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_test_data(years, category):\n",
    "    '''\n",
    "    Get a subset of the test data for evaluation\n",
    "    '''\n",
    "    # Create test samples\n",
    "    # Load full catalog and select EF 3+ tornadoes\n",
    "    os.environ['TORNET_ROOT'] = '/Users/dana/Desktop/ML/tornet_project/dataset'\n",
    "    data_root=os.environ['TORNET_ROOT']\n",
    "\n",
    "    catalog_path = os.path.join(data_root,'catalog.csv')\n",
    "    if not os.path.exists(catalog_path):\n",
    "        raise RuntimeError('Unable to find catalog.csv at '+data_root)\n",
    "            \n",
    "    catalog = pd.read_csv(catalog_path,parse_dates=['start_time','end_time'])\n",
    "\n",
    "    catalog = catalog[(catalog.start_time.dt.year.isin(years)) & (catalog['category'].isin(category))]\n",
    "    # catalog = catalog[(catalog.start_time.dt.year.isin([2021]))]\n",
    "\n",
    "    ds_test = KerasDataLoader(data_root=data_root,\n",
    "                            data_type='test',\n",
    "                            random_state=1234,\n",
    "                            catalog=catalog,\n",
    "                            batch_size = 64, \n",
    "                            use_multiprocessing = True)\n",
    "\n",
    "    return ds_test\n",
    "\n",
    "def evalate_model(model, ds_test):\n",
    "    '''\n",
    "    Evaluate the model on the test data\n",
    "    '''\n",
    "    # Evaluate the model\n",
    "    # model = keras.models.load_model('baselinecnn.keras')\n",
    "    # Compute various metrics\n",
    "    from_logits = True\n",
    "    metrics = [keras.metrics.AUC(from_logits=from_logits, name='AUC', num_thresholds=2000),\n",
    "               keras.metrics.AUC(from_logits=from_logits,\n",
    "                                 curve='PR', name='AUCPR', num_thresholds=2000),\n",
    "               tfm.BinaryAccuracy(from_logits, name='BinaryAccuracy'),\n",
    "               tfm.TruePositives(from_logits, name='TruePositives'),\n",
    "               tfm.FalsePositives(from_logits, name='FalsePositives'),\n",
    "               tfm.TrueNegatives(from_logits, name='TrueNegatives'),\n",
    "               tfm.FalseNegatives(from_logits, name='FalseNegatives'),\n",
    "               tfm.Precision(from_logits, name='Precision'),\n",
    "               tfm.Recall(from_logits, name='Recall'),\n",
    "               tfm.F1Score(from_logits=from_logits, name='F1')]\n",
    "    model.compile(metrics=metrics)\n",
    "\n",
    "    scores = model.evaluate(ds_test)\n",
    "    scores = {m.name: scores[k+1] for k, m in enumerate(metrics)}\n",
    "\n",
    "    logging.info(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3d504d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for category: ['TOR', 'NUL', 'WRN']\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 2s/step - AUC: 0.7503 - AUCPR: 0.1048 - BinaryAccuracy: 0.9625 - F1: 0.0267 - FalseNegatives: 132.3661 - FalsePositives: 5.0268 - Precision: 0.2991 - Recall: 0.0140 - TrueNegatives: 3475.4644 - TruePositives: 1.5179 - loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'AUC': 0.7350379228591919, 'AUCPR': 0.0930003821849823, 'BinaryAccuracy': 0.96025550365448, 'TruePositives': 2.0, 'FalsePositives': 10.0, 'TrueNegatives': 6763.0, 'FalseNegatives': 270.0, 'Precision': 0.1666666716337204, 'Recall': 0.007352941203862429, 'F1': 0.014084498398005962}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Evaluation for category: ['TOR', 'NUL']\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 2s/step - AUC: 0.8437 - AUCPR: 0.2794 - BinaryAccuracy: 0.9429 - F1: 0.0047 - FalseNegatives: 135.6400 - FalsePositives: 2.5333 - Precision: 0.0882 - Recall: 0.0024 - TrueNegatives: 2291.2932 - TruePositives: 0.5067 - loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'AUC': 0.8305799961090088, 'AUCPR': 0.23372143507003784, 'BinaryAccuracy': 0.9409633278846741, 'TruePositives': 2.0, 'FalsePositives': 7.0, 'TrueNegatives': 4413.0, 'FalseNegatives': 270.0, 'Precision': 0.2222222238779068, 'Recall': 0.007352941203862429, 'F1': 0.014234868809580803}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Evaluation for category: ['TOR', 'WRN']\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - AUC: 0.5395 - AUCPR: 0.1298 - BinaryAccuracy: 0.8907 - F1: 0.0074 - FalseNegatives: 148.8139 - FalsePositives: 1.6047 - Precision: 0.2240 - Recall: 0.0038 - TrueNegatives: 1252.3489 - TruePositives: 0.8140 - loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'AUC': 0.5555665493011475, 'AUCPR': 0.13916750252246857, 'BinaryAccuracy': 0.8960000276565552, 'TruePositives': 2.0, 'FalsePositives': 3.0, 'TrueNegatives': 2350.0, 'FalseNegatives': 270.0, 'Precision': 0.4000000059604645, 'Recall': 0.007352941203862429, 'F1': 0.014440430328249931}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "categories = [['TOR', 'NUL', 'WRN'], ['TOR', 'NUL'], ['TOR', 'WRN']]\n",
    "years = [2021,2022]\n",
    "for category in categories:\n",
    "    print('Evaluation for category:', category)\n",
    "    ds_test = get_subset_test_data(years, category)\n",
    "    evalate_model(baselinecnn, ds_test)\n",
    "    print('---------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efc89d9",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bff8d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "model_file = 'baselinecnn.keras'\n",
    "cnn = keras.models.load_model(model_file,compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c42e3c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test samples in the catalog: 48232\n",
      "Number of test samples in the dataset: 1762\n",
      "\u001b[1m1762/1762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 122ms/step - AUC: 0.7499 - AUCPR: 0.1054 - BinaryAccuracy: 0.9625 - F1: 0.0271 - FalseNegatives: 128.9949 - FalsePositives: 4.9070 - Precision: 0.3025 - Recall: 0.0142 - TrueNegatives: 3392.5872 - TruePositives: 1.5054 - loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'AUC': 0.7350379228591919, 'AUCPR': 0.0930003821849823, 'BinaryAccuracy': 0.96025550365448, 'TruePositives': 2.0, 'FalsePositives': 10.0, 'TrueNegatives': 6763.0, 'FalseNegatives': 270.0, 'Precision': 0.1666666716337204, 'Recall': 0.007352941203862429, 'F1': 0.014084498398005962}\n"
     ]
    }
   ],
   "source": [
    "ds_test = get_subset_test_data(['TOR', 'NUL', 'WRN'])\n",
    "evalate_model(cnn, ds_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7b76794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the pretrained model for inference from huggingface\n",
    "from huggingface_hub import hf_hub_download\n",
    "model_file = hf_hub_download(repo_id=\"tornet-ml/tornado_detector_baseline_v1\", \n",
    "                             filename=\"tornado_detector_baseline.keras\")\n",
    "\n",
    "# Alternatively, you can manually download the .keras file and put in the ../models/ directory\n",
    "# https://huggingface.co/tornet-ml/tornado_detector_baseline_v1\n",
    "#model_file = '../models/tornado_detector_baseline.keras' \n",
    "\n",
    "# Load pretrained model\n",
    "pretrained_cnn = keras.models.load_model(model_file,compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "416d1d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for category with pretrained model: ['TOR', 'NUL', 'WRN']\n",
      "Evaluation for category: ['TOR', 'NUL', 'WRN']\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 2s/step - AUC: 0.8788 - AUCPR: 0.3350 - BinaryAccuracy: 0.9524 - F1: 0.4076 - FalseNegatives: 75.2232 - FalsePositives: 92.4554 - Precision: 0.3789 - Recall: 0.4439 - TrueNegatives: 3388.0356 - TruePositives: 58.6607 - loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'AUC': 0.8783445358276367, 'AUCPR': 0.33739280700683594, 'BinaryAccuracy': 0.9535840749740601, 'TruePositives': 115.0, 'FalsePositives': 170.0, 'TrueNegatives': 6603.0, 'FalseNegatives': 157.0, 'Precision': 0.4035087823867798, 'Recall': 0.4227941036224365, 'F1': 0.4129263162612915}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Evaluation for category with pretrained model: ['TOR', 'NUL']\n",
      "Evaluation for category: ['TOR', 'NUL']\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 2s/step - AUC: 0.9427 - AUCPR: 0.6879 - BinaryAccuracy: 0.9661 - F1: 0.6163 - FalseNegatives: 73.6933 - FalsePositives: 12.5467 - Precision: 0.8482 - Recall: 0.4858 - TrueNegatives: 2281.2800 - TruePositives: 62.4533 - loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'AUC': 0.9288573265075684, 'AUCPR': 0.6525731086730957, 'BinaryAccuracy': 0.9618499279022217, 'TruePositives': 115.0, 'FalsePositives': 22.0, 'TrueNegatives': 4398.0, 'FalseNegatives': 157.0, 'Precision': 0.8394160866737366, 'Recall': 0.4227941036224365, 'F1': 0.5623471736907959}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Evaluation for category with pretrained model: ['TOR', 'WRN']\n",
      "Evaluation for category: ['TOR', 'WRN']\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - AUC: 0.7658 - AUCPR: 0.3699 - BinaryAccuracy: 0.8730 - F1: 0.4099 - FalseNegatives: 88.0930 - FalsePositives: 84.3256 - Precision: 0.4127 - Recall: 0.4078 - TrueNegatives: 1169.6279 - TruePositives: 61.5349 - loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'AUC': 0.7834585905075073, 'AUCPR': 0.3812639117240906, 'BinaryAccuracy': 0.883809506893158, 'TruePositives': 115.0, 'FalsePositives': 148.0, 'TrueNegatives': 2205.0, 'FalseNegatives': 157.0, 'Precision': 0.4372623562812805, 'Recall': 0.4227941036224365, 'F1': 0.4299064576625824}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "categories = [['TOR', 'NUL', 'WRN'], ['TOR', 'NUL'], ['TOR', 'WRN']]\n",
    "years = [2021,2022]\n",
    "for category in categories:\n",
    "    print('Evaluation for category with pretrained model:', category)\n",
    "    print('Evaluation for category:', category)\n",
    "    ds_test = get_subset_test_data(years, category)\n",
    "    evalate_model(pretrained_cnn, ds_test)\n",
    "    print('---------------------------------------------------------')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
